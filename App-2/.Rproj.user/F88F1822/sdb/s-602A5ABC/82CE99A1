{
    "contents" : "---\ntitle: \"Comaprison of off-road glance distribution focusing outliers\"\nauthor: \"Joonbum Lee\"\ndate: \"February 29, 2016\"\noutput: html_document\n---\n\nCode to process and analyze glance data from five studies.\n\n**Load library and custom functions**\n```{r}\nlibrary(plyr)\nlibrary(ggplot2)\nlibrary(plyr)\nlibrary(DBI)\nlibrary(RPostgreSQL)\nlibrary(gdata)\nlibrary(dplyr)\nlibrary(reshape2)\nlibrary(ez)\nlibrary(lme4)\nlibrary(agelabr)\nlibrary(corrplot)\nlibrary(scales)\nlibrary(caret)\nlibrary(randomForest)\n\nsource(\"~/Dropbox/Works/R codes/MIT/Functions/sss.score.R\")\nsource(\"~/Dropbox/Works/R codes/MIT/Functions/dbq.score.R\")\nsource(\"~/Dropbox/Works/R codes/MIT/Jon code/new glance functions.R\")\nsource(\"~/Dropbox/Works/R codes/MIT/Functions/add.task time.r\")\nsource(\"~/Dropbox/Works/R codes/MIT/Functions/cor.mtest.R\")\nsource(\"~/Dropbox/Works/R codes/MIT/Functions/multiplot.R\")\n```\n\n**Pull glance data from six studies**\n```{r}\n# pull 2013a glance data and exclude unused glance locations and glances to \"road\"\noff.glance.2013a <- glance.from.db('2013-onrd-a') %>% glance.triage %$% data.reduced %>% subset(!(look %in% c(\"road\",\"poor video quality\",\"other\",\"eyes not visible\",\"uncodable\")))\n# add study name and renumber subject id so subject id could be unique across all studies\noff.glance.2013a$study_name <- \"2013a\"\noff.glance.2013a$new_subject <- off.glance.2013a$subject + 1000\n \n# pull whole data to calculate task time\nglance.2013a <- glance.from.db('2013-onrd-a') %>% glance.triage %$% data.reduced\n# add study name and renumber subject id so subject id could be unique across all studies\nglance.2013a$study_name <- \"2013a\"\nglance.2013a$new_subject <- glance.2013a$subject + 1000\nglance.2013a <- add.time(glance.2013a, \"new_subject\", \"task\")\n \n# pull demographic data (expert modes were exlcluded)\ndemo.2013a<-read.csv(\"~/Documents/Local data archive/AgeLab2013a/Subject list/2013a demographics all 2014-01-24.csv\")%>%subset(select=1:3)\ng2013a<-join(off.glance.2013a, demo.2013a, by=\"subject\")%>%na.omit\n# add vehicle name\ng2013a$car<-\"MKS\"\n# add DBQ scores\ndbq.2013a<-read.csv(\"~/Documents/Local data archive/AgeLab2013a/preq/2013a_PreQ_newcoding copy.csv\")%>%dbq.score()%>%subset(select=c(\"subject\",\"DBQ_E_mean\",\"DBQ_V_mean\",\"DBQ_L_mean\"))\ng2013a<-join(g2013a, dbq.2013a, by=\"subject\")\n \n# pull 2013g glance data and exclude unused glance locations and glances to \"road\"\ndata.glance.2013g <- glance.from.db('2013-onrd-g')\ndata.glance.triage.2013g<-glance.triage(data.glance.2013g)\noff.glance.2013g<-data.glance.triage.2013g$data.reduced %>% subset(!(look %in% c(\"road\",\"poor video quality\",\"other\",\"eyes not visible\",\"uncodable\")))\n# add study name and renumber subject id so subject id could be unique across all studies\noff.glance.2013g$study_name <- \"2013g\"\noff.glance.2013g$new_subject <- off.glance.2013g$subject + 2000\n \n# pull whole data to calculate task time\nglance.2013g <- glance.from.db('2013-onrd-g') %>% glance.triage %$% data.reduced\n# add study name and renumber subject id so subject id could be unique across all studies\nglance.2013g$study_name <- \"2013g\"\nglance.2013g$new_subject <- glance.2013g$subject + 2000\nglance.2013g <- add.time(glance.2013g, \"new_subject\", \"task\")\n \n# pull demographic data\ndemo.2013g<-read.csv(\"~/Documents/Local data archive/AgeLab2013g/Subject list/2013g demographics 2014-04-22.csv\")%>%subset(select=c(1,2,3,5))\ng2013g<-join(off.glance.2013g, demo.2013g, by=\"subject\")%>%na.omit\nlevels(g2013g$car)[levels(g2013g$car)==\"Chevy\"] <- \"Equinox\"\nlevels(g2013g$car)[levels(g2013g$car)==\"Volvo\"] <- \"XC60\"\n# add DBQ scores\ndbq.2013g<-read.csv(\"~/Documents/Local data archive/AgeLab2013g/Preq/2013g_PreQ copy.csv\")%>%dbq.score()%>%subset(select=c(\"subject\",\"DBQ_E_mean\",\"DBQ_V_mean\",\"DBQ_L_mean\"))\ng2013g<-join(g2013g, dbq.2013g, by=\"subject\")\n \n \n# pull 2014b glance data and exclude unused glance locations and glances to \"road\"\ndata.glance.2014b <- glance.from.db('2014-onrd-b')\ndata.glance.triage.2014b<-glance.triage(data.glance.2014b)\noff.glance.2014b<-data.glance.triage.2014b$data.reduced %>% subset(!(look %in% c(\"road\",\"poor video quality\",\"other\",\"eyes not visible\",\"uncodable\")))\n# add study name and renumber subject id so subject id could be unique across all studies\noff.glance.2014b$study_name <- \"2014b\"\noff.glance.2014b$new_subject <- off.glance.2014b$subject + 3000\n \n# pull whole data to calculate task time\nglance.2014b <- glance.from.db('2014-onrd-b') %>% glance.triage %$% data.reduced\n# add study name and renumber subject id so subject id could be unique across all studies\nglance.2014b$study_name <- \"2014b\"\nglance.2014b$new_subject <- glance.2014b$subject + 3000\nglance.2014b <- add.time(glance.2014b, \"new_subject\", \"task\")\n \n# pull demographic data\ndemo.2014b<-read.csv(\"~/Documents/Local data archive/AgeLab2014b/Subject list/2014b demographics.csv\")%>%subset(select=1:3)\ng2014b<-join(off.glance.2014b, demo.2014b, by=\"subject\")%>%na.omit\ng2014b$car<-\"Impala\"\n# add DBQ scores\ndbq.2014b<-read.csv(\"~/Documents/Local data archive/AgeLab2014b/Preq/2014b Pre Q coding copy.csv\")%>%dbq.score()%>%subset(select=c(\"subject\",\"DBQ_E_mean\",\"DBQ_V_mean\",\"DBQ_L_mean\"))\ng2014b<-join(g2014b, dbq.2014b, by=\"subject\")\n \n \n# pull 2014t glance data and exclude unused glance locations and glances to \"road\"\ndata.glance.2014t <- glance.from.db('2014-onrd-t')\ndata.glance.triage.2014t<-glance.triage(data.glance.2014t)\noff.glance.2014t<-data.glance.triage.2014t$data.reduced %>% subset(!(look %in% c(\"road\",\"poor video quality\",\"other\",\"eyes not visible\",\"uncodable\")))\n# add study name and renumber subject id so subject id could be unique across all studies\noff.glance.2014t$study_name <- \"2014t\"\noff.glance.2014t$new_subject <- off.glance.2014t$subject + 4000\n \n# pull whole data to calculate task time\nglance.2014t <- glance.from.db('2014-onrd-t') %>% glance.triage %$% data.reduced\n# add study name and renumber subject id so subject id could be unique across all studies\nglance.2014t$study_name <- \"2014t\"\nglance.2014t$new_subject <- glance.2014t$subject + 4000\nglance.2014t <- add.time(glance.2014t, \"new_subject\", \"task\")\n \n# pull demographic data\ndemo.2014t<-read.csv(\"~/Documents/Local data archive/AgeLab2014t/2014t demographics.csv\")%>%subset(select=1:3)\ng2014t<-join(off.glance.2014t, demo.2014t, by=\"subject\")%>%na.omit\ng2014t$car<-\"CLA\"\n# add DBQ scores\ndbq.2014t<-read.csv(\"~/Documents/Local data archive/AgeLab2014t/2014t Pre Q Coding.csv\")%>%dbq.score()%>%subset(select=c(\"subject\",\"DBQ_E_mean\",\"DBQ_V_mean\",\"DBQ_L_mean\"))\ng2014t<-join(g2014t, dbq.2014t, by=\"subject\")\n\n \n# pull 2015b glance data and exclude unused glance locations and glances to \"road\"\ndata.glance.2015b <- glance.from.db('2015-onrd-b')\ndata.glance.triage.2015b<-glance.triage(data.glance.2015b)\noff.glance.2015b<-data.glance.triage.2015b$data.reduced %>% subset(!(look %in% c(\"road\",\"poor video quality\",\"other\",\"eyes not visible\",\"uncodable\")))\n# add study name and renumber subject id so subject id could be unique across all studies\noff.glance.2015b$study_name <- \"2015b\"\noff.glance.2015b$new_subject <- off.glance.2015b$subject + 6000\n\n# pull whole data to calculate task time\nglance.2015b<- glance.from.db('2015-onrd-b') %>% glance.triage %$% data.reduced\n# add study name and renumber subject id so subject id could be unique across all studies\nglance.2015b$study_name <- \"2015b\"\nglance.2015b$new_subject <- glance.2015b$subject + 6000\nglance.2015b <- add.time(glance.2015b, \"new_subject\", \"task\")\n \n# pull demographic data\ndemo.2015b<-read.csv(\"~/Documents/Local data archive/AgeLab2015b/2015b demographics.csv\")%>%subset(select=1:3)\ng2015b<-join(off.glance.2015b, demo.2015b, by=\"subject\")%>%na.omit\ng2015b$car<-\"Corolla\"\n# add DBQ scores\ndbq.2015b<-read.csv(\"~/Documents/Local data archive/AgeLab2015b/2015b Pre Q Coding.csv\")%>%dbq.score()%>%subset(select=c(\"subject\",\"DBQ_E_mean\",\"DBQ_V_mean\",\"DBQ_L_mean\"))\ng2015b<-join(g2015b, dbq.2015b, by=\"subject\")\n```\n\n**Save csv files**\n```{r}\n#write.csv(g2013a, \"~/Documents/Local data archive/AgeLab2013a/2016 02 23 off-road glances and demo data and DBQ for 2013a including expert mode.csv\", row.names = FALSE)\n#write.csv(g2013g, \"~/Documents/Local data archive/AgeLab2013g/2016 02 23 off-road glances and demo data and DBQ for 2013g\", row.names = FALSE)\n#write.csv(g2014b, \"~/Documents/Local data archive/AgeLab2014b/2016 02 23 off-road glances and demo data and DBQ for 2014b.csv\", row.names = FALSE)\n#write.csv(g2014t, \"~/Documents/Local data archive/AgeLab2014t/2016 02 23 off-road glances and demo data and DBQ for 2014t.csv\", row.names = FALSE)\n#write.csv(g2015b, \"~/Documents/Local data archive/AgeLab2015b/2016 02 23 off-road glances and demo data and DBQ for 2015b.csv\", row.names = FALSE)\n\n#write.csv(glance.2013a, \"~/Documents/Local data archive/AgeLab2013a/2016 02 24 all glances and task time for 2013a.csv\", row.names = FALSE)\n#write.csv(glance.2013g, \"~/Documents/Local data archive/AgeLab2013g/2016 02 24 all glances and task time for 2013g.csv\", row.names = FALSE)\n#write.csv(glance.2014b, \"~/Documents/Local data archive/AgeLab2014b/2016 02 24 all glances and task time for 2014b.csv\", row.names = FALSE)\n#write.csv(glance.2014t, \"~/Documents/Local data archive/AgeLab2014t/2016 02 24 all glances and task time for 2014t.csv\", row.names = FALSE)\n#write.csv(glance.2015b, \"~/Documents/Local data archive/AgeLab2015b/2016 02 24 all glances and task time for 2015b.csv\", row.names = FALSE)\n\n# write.csv(g2013a,\"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 off-road glances and demo data and DBQ for 2013a including expert mode.csv\", row.names = FALSE)\n# write.csv(g2013g, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 off-road glances and demo data and DBQ for 2013g\", row.names = FALSE)\n# write.csv(g2014b, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 off-road glances and demo data and DBQ for 2014b.csv\", row.names = FALSE)\n# write.csv(g2014t, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 off-road glances and demo data and DBQ for 2014t.csv\", row.names = FALSE)\n# write.csv(g2015b, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 off-road glances and demo data and DBQ for 2015b.csv\", row.names = FALSE)\n# \n# write.csv(glance.2013a, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 all glances and task time for 2013a.csv\", row.names = FALSE)\n# write.csv(glance.2013g, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 all glances and task time for 2013g.csv\", row.names = FALSE)\n# write.csv(glance.2014b, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 all glances and task time for 2014b.csv\", row.names = FALSE)\n# write.csv(glance.2014t, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 all glances and task time for 2014t.csv\", row.names = FALSE)\n# write.csv(glance.2015b, \"~/Dropbox/Works/AgeLab/JB and Jon/Data/2016 03 25 all glances and task time for 2015b.csv\", row.names = FALSE)\n```\n\n**Descriptive statistics**\n```{r}\n# files including only off-road glances\ng2013a<-read.csv(\"~/Documents/Local data archive/AgeLab2013a/2016 02 23 off-road glances and demo data and DBQ for 2013a including expert mode.csv\")\ng2013g<-read.csv(\"~/Documents/Local data archive/AgeLab2013g/2016 02 23 off-road glances and demo data and DBQ for 2013g.csv\")\ng2014b<-read.csv(\"~/Documents/Local data archive/AgeLab2014b/2016 02 23 off-road glances and demo data and DBQ for 2014b.csv\")\ng2014t<-read.csv(\"~/Documents/Local data archive/AgeLab2014t/2016 02 23 off-road glances and demo data and DBQ for 2014t.csv\")\ng2015b<-read.csv(\"~/Documents/Local data archive/AgeLab2015b/2016 02 23 off-road glances and demo data and DBQ for 2015b.csv\")\n\n# files including all glances\nglance.2013a<-read.csv(\"~/Documents/Local data archive/AgeLab2013a/2016 02 24 all glances and task time for 2013a.csv\")\nglance.2013g<-read.csv(\"~/Documents/Local data archive/AgeLab2013g/2016 02 24 all glances and task time for 2013g.csv\")\nglance.2014b<-read.csv(\"~/Documents/Local data archive/AgeLab2014b/2016 02 24 all glances and task time for 2014b.csv\")\nglance.2014t<-read.csv(\"~/Documents/Local data archive/AgeLab2014t/2016 02 24 all glances and task time for 2014t.csv\")\nglance.2015b<-read.csv(\"~/Documents/Local data archive/AgeLab2015b/2016 02 24 all glances and task time for 2015b.csv\")\n\n# combine all studies\nall.off <- rbind(g2013a,g2013g,g2014b,g2014t,g2015b) # 2015a was intentionally excluded to increase consistency acorss studies (it was ACC study)\n\n# remane levels of gender variable\nlevels(all.off$gender)[levels(all.off$gender)==\"M\"] <- \"Male\"\nlevels(all.off$gender)[levels(all.off$gender)==\"F\"] <- \"Female\"\n```\n\n**Descriptive statistics**\n```{r}\n# N\nlength(unique(all.off$new_subject)) # 288 + 32 (Experts from 2013a)\n# mean duration\nmean(all.off$duration) # 0.8\n# SD duration\nsd(all.off$duration) # 0.42\n# Max\nmax(all.off$duration) # 12.53\n# Min\nmin(all.off$duration) # 12.53\n# Mean + 2 SD\nmean(all.off$duration)+2*sd(all.off$duration) # 1.65\n```\n\n**Labeling task type and modality**\n```{r}\n# add task type (baseline vs. secondary task)\nall.off$task_type <-\"Driving with secondary tasks\"\nall.off$task_type[grepl(\"base\",all.off$task)] <- \"Just driving\"\n\n# exclude smartphone tasks from 2013g study\nall.off<-subset(all.off, !(task%in%c(\"m_p_1\",\"m_p_2\",\"m_p_3\",\"m_p_4\",\"m_p_base\", \"nav_p_1\",\"nav_p_2\",\"nav_p_3\",\"nav_p_entry_1\",\"nav_p_entry_2\",\"nav_p_entry_3\",\"nav_p_base\", \"nav_p_cancel_1\",\"nav_p_cancel_2\",\"nav_p_cancel_3\",\"nav_p_cancel1\",\"nav_p_cancel2\",\"nav_p_cancel3\",\"v_p_1\",\"v_p_2\",\"v_p_3\",\"v_p_4\",\"v_p_base\")))\n\n# add task modality (AV vs. VM)\nall.off$task_modality <-\"Auditory-vocal tasks\"\nall.off$task_modality[grepl(\"base\",all.off$task)] <- \"Just driving\"\nall.off$task_modality[all.off$task%in%c(\"radiom_1\",\"radiom_2\",\"radiom_4\",\"radiom_6\",\"radio_m1\",\"radio_m2\",\"radio_m4\",\"radio_m6\")] <-\"Visual-manual tasks\"\n\nall.off$task_type <- factor(all.off$task_type, levels = c(\"Just driving\", \"Driving with secondary tasks\"))\nall.off$task_modality <- factor(all.off$task_modality, levels = c(\"Just driving\", \"Auditory-vocal tasks\", \"Visual-manual tasks\"))\n\n# plot distribution of off-road glances (N=320)\nggplot(all.off, aes(x=duration))+geom_histogram(binwidth=0.1,fill=\"skyblue\")+theme_bw(16)+ylab(\"Count\")+xlab(\"Single off-road glance duration (sec)\")+geom_vline(aes(xintercept=mean(duration)), colour=\"navyblue\", linetype=4)+geom_vline(aes(xintercept=mean(duration)+2*sd(duration)), colour=\"red\", linetype=2)+geom_vline(xintercept=2, colour=\"forestgreen\", linetype=3)+annotate(\"text\", x=mean(all.off$duration), y=-2, label=\"Mean\")+annotate(\"text\", x=mean(all.off$duration)+2*sd(all.off$duration)-0.1, y=19000, label=\"Mean + 2 SD\", colour=\"red\")+annotate(\"text\", x=2.1, y=-2, label=\"2 seconds\", colour=\"forestgreen\")\n\nggplot(over2, aes(x=duration,group=task_modality))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"skyblue\")+theme_bw(16)+ylab(\"Density\")+xlab(\"Single off-road glance duration (sec)\")+facet_grid(task_modality~.)\n\nggplot(all.off, aes(x=duration,group=task_type))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"skyblue\")+theme_bw(16)+ylab(\"Density of off-road glance\")+xlab(\"Single off-road glance duration (sec)\")+facet_grid(task_type~.)\n\nggplot(all.off, aes(x=duration,group=task_modality))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"skyblue\")+theme_bw(16)+ylab(\"Density of off-road glance\")+xlab(\"Single off-road glance duration (sec)\")+facet_grid(task_modality~.)\n\n#\nggplot(all.off, aes(x=duration,group=task_modality))+geom_density(aes(x=duration, y=..scaled..,fill=task_modality,linetype=task_modality), alpha=I(.3))+theme_bw(16)+ylab(\"Density\")+xlab(\"Single off-road glance duration (sec)\")+scale_fill_manual(values=c(\"navy\",\"yellow\",\"cyan\"))+theme(legend.position=\"top\")\n\nggplot(all.off, aes(x=duration,group=task_type))+geom_histogram(aes(y=..density..,fill=task_type),binwidth=0.1)+theme_bw(16)+ylab(\"Density of off-road glance\")+xlab(\"Single off-road glance duration (sec)\")\nggplot(all.off, aes(x=duration,group=task_modality))+geom_histogram(aes(y=..density..,fill=task_modality),binwidth=0.1)+theme_bw(16)+ylab(\"Density of off-road glance\")+xlab(\"Single off-road glance duration (sec)\")\n\n#\nggplot(all.off, aes(x=duration, group=task_modality))+stat_ecdf(aes(colour=task_modality, linetype=task_modality),size=0.7)+theme_bw(16)+ylab(\"Cumulative probability\")+xlab(\"Off-road glance duration (sec)\")+theme(legend.position=\"top\")\n\nggplot(all.off, aes(x=duration, group=task_type))+stat_ecdf(aes(colour=task_type, linetype=task_type),size=0.7)+theme_bw(16)+ylab(\"Cumulative probability\")+xlab(\"Off-road glance duration (sec)\")+theme(legend.position=\"top\")\n\nggplot(all.off, aes(x=duration,group=task_type))+geom_histogram(aes(y=..count../sum(..count..)),binwidth=0.1,fill=\"skyblue\")+theme_bw(16)+ylab(\"Density of off-road glance\")+xlab(\"Single off-road glance duration (sec)\")+facet_grid(task_type~.)+scale_y_continuous(labels = percent_format())\nggplot(all.off, aes(x=duration,group=task_type))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"skyblue\")+theme_bw(16)+ylab(\"Density of off-road glance\")+xlab(\"Single off-road glance duration (sec)\")+facet_grid(task_type~.)\nggplot(all.off, aes(x=duration))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"skyblue\")+theme_bw(16)+ylab(\"Density of off-road glance\")+xlab(\"Single off-road glance duration (sec)\")+scale_y_continuous(labels = percent_format())\n\n```\n**Distribution of off-road glance duration**\n```{r, fig.width=12, fig.height=5}\nggplot(all.off, aes(x=duration))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count\")+xlab(\"Single off-road glance duration (sec)\")+geom_vline(xintercept=2, colour=\"red\", linetype=3)+geom_vline(xintercept=1.64, colour=\"pink\", linetype=2)+geom_vline(xintercept=0.8, colour=\"salmon\", linetype=4)+ggtitle(\"Distribution of off-road glance duration (mean, mean+2SD, 2 seconds)\")\nggplot(all.off, aes(x=duration))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count\")+xlab(\"Single off-road glance duration (sec)\")+scale_x_continuous(lim=c(2,13))+ggtitle(\"Distribution of off-road glance duration (over 2 seconds)\")\nggplot(all.off, aes(x=duration))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count\")+xlab(\"Single off-road glance duration (sec)\")+scale_x_continuous(lim=c(4,13))+ggtitle(\"Distribution of off-road glance duration (over 4 seconds)\")\nggplot(all.off, aes(x=duration,group=car))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count\")+xlab(\"Single off-road glance duration (sec)\")+geom_vline(xintercept=2, colour=\"salmon\", linetype=3)+scale_x_continuous(lim=c(2,13))+facet_wrap(~car)\n```\n\n**Investigation of long off-road glances: part 1**\n```{r, fig.width=12, fig.height=5}\nover2 <- subset(all.off, duration > 2) #1469\nover2$task <-as.factor(over2$task)\nlength(unique(over2$new_subject)) # 183\nunique(all.off$task)\nradio.off<-subset(all.off, task%in%c(\"radiom_4\",\"radio_m4\",\"nav_entry_1\",\"nav_1\",\"nav_c_entry_1\",\"nav_c_1\"))\nradio.off$task <- as.factor(radio.off$task)\nlevels(radio.off$task)[levels(radio.off$task)==\"radio_m4\"] <- \"radiom_4\"\nlevels(radio.off$task)[levels(radio.off$task)==\"nav_c_1\"] <- \"nav_entry_1\"\nlevels(radio.off$task)[levels(radio.off$task)==\"nav_c_entry_1\"] <- \"nav_entry_1\"\nlevels(radio.off$task)[levels(radio.off$task)==\"nav_1\"] <- \"nav_entry_1\"\nggplot(radio.off, aes(x=duration))+geom_histogram(binwidth=0.1,fill=\"pink\",colour=\"black\")+theme_bw(16)+facet_grid(car~task)+xlab(\"Off-road glance duration (sec)\")+ylab(\"Count\")\n\n# by glance locations\nggplot(over2, aes(x=look))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")\n# by glance locations x car\nggplot(over2, aes(x=look))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")+facet_grid(.~car)+theme(axis.text.x = element_text(angle = 45, hjust = 1))\nggplot(over2, aes(x=look))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")+facet_wrap(~car)+theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\n# by glance locations x car (percentage)\nggplot(over2, aes(x=look, group=car))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Percentage of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_grid(.~car)+scale_y_continuous(labels = percent_format())\nggplot(over2, aes(x=look, group=car))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Density of long\\n off-road glances (%)\")+xlab(\"Glance locations\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_wrap(~car)+scale_y_continuous(labels = percent_format())\n\nimpala.over2<-subset(over2, car==\"Impala\")\nggplot(impala.over2, aes(x=look))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")+ggtitle(\"Impala\")\n\n# by tasks (using raw task names)\nggplot(over2, aes(x=task))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n**Renaming task codes**\n```{r}\n# radiom_4 and radiom_6\nlevels(over2$task)[levels(over2$task)==\"radio_m4\"] <- \"radiom_4\"\nlevels(over2$task)[levels(over2$task)==\"radio_m6\"] <- \"radiom_6\"\n\n# nav entry\nlevels(over2$task)[levels(over2$task)==\"nav_c_1\"] <- \"nav_entry_1\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_2\"] <- \"nav_entry_2\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_3\"] <- \"nav_entry_3\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_entry_1\"] <- \"nav_entry_1\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_entry_2\"] <- \"nav_entry_2\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_entry_3\"] <- \"nav_entry_3\"\nlevels(over2$task)[levels(over2$task)==\"nav_1\"] <- \"nav_entry_1\"\nlevels(over2$task)[levels(over2$task)==\"nav_2\"] <- \"nav_entry_2\"\nlevels(over2$task)[levels(over2$task)==\"nav_3\"] <- \"nav_entry_3\"\n\nlevels(over2$task)[levels(over2$task)==\"nav_cancel1\"] <- \"nav_cancel_1\"\nlevels(over2$task)[levels(over2$task)==\"nav_cancel2\"] <- \"nav_cancel_2\"\nlevels(over2$task)[levels(over2$task)==\"nav_cancel3\"] <- \"nav_cancel_3\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_cancel1\"] <- \"nav_cancel_1\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_cancel2\"] <- \"nav_cancel_2\"\nlevels(over2$task)[levels(over2$task)==\"nav_c_cancel3\"] <- \"nav_cancel_3\"\n```\n\n**Investigation of long off-road glances: part 2**\n```{r, fig.width=12, fig.height=5}\n# set 1: two nav entry tasks, two nav cancel tasks, two VM radio tuning tasks for all studies\ntwonav<-subset(over2, task%in%c(\"nav_entry_1\",\"nav_entry_2\",\"nav_cancel_1\",\"nav_cancel_2\",\"radiom_4\",\"radiom_6\"))\n\n# by task\nggplot(twonav, aes(x=task))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))\n# by task x car\nggplot(twonav, aes(x=task))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_grid(.~car)\n# by task x car (percentage)\nggplot(twonav, aes(x=task, group=car))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Density of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_grid(.~car)+scale_y_continuous(labels = percent_format())\nggplot(twonav, aes(x=task, group=car))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Density of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_wrap(~car)+scale_y_continuous(labels = percent_format())\n\n# by task x glance locations\nggplot(twonav, aes(x=look))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_wrap(~task)\nggplot(twonav, aes(x=look, group=task))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Density of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_wrap(~task)\n\n# set 2: three nave entry tasks, three nav cancel tasks, two VM radio tuning tasks for all studies except 2013a\nthreenav<-subset(over2, car!=\"MKS\")%>%subset(task%in%c(\"nav_entry_1\",\"nav_entry_2\",\"nav_entry_3\",\"nav_cancel_1\",\"nav_cancel_2\",\"nav_cancel_3\",\"radiom_4\",\"radiom_6\"))\n# by task\nggplot(threenav, aes(x=task))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))\n# by task x car\nggplot(threenav, aes(x=task))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_grid(.~car)\n# by task x car (percentage)\nggplot(threenav, aes(x=task, group=car))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Percentage of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_grid(.~car)+scale_y_continuous(labels = percent_format())\nggplot(threenav, aes(x=task, group=car))+geom_histogram(aes(y=..density..),binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Density of long off-road glances\\n (over 2 seconds)\")+xlab(\"Tasks\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_wrap(~car)+scale_y_continuous(labels = percent_format())\n\n# by task x glance locations\nggplot(threenav, aes(x=look))+geom_histogram(binwidth=0.1,fill=\"navyblue\")+theme_bw(16)+ylab(\"Count of long off-road glances\\n (over 2 seconds)\")+xlab(\"Glance locations\")+theme(axis.text.x = element_text(angle = 45, hjust = 1))+facet_grid(.~task)\n```\n\n**Add task time (to calculate per minute variables) and exclude baseline periods**\n```{r}\n# exclude baseline periods\ntask.off<-subset(all.off, !(grepl(\"base\", task)))\n\n# create a task time table\ntasktime.table <- rbind(glance.2013a, glance.2013g, glance.2014b, glance.2014t, glance.2015b)%>%ddply(.(new_subject, task), summarise, task_time=max(task_time))\n\n# add a flag for long glances\ntask.off$long_glance<-0\ntask.off$long_glance[task.off$duration>=2]<-1\n```\n\n**create a summary table**\n```{r}\ntask.off.sum <- ddply(task.off, .(new_subject, age, gender, car, task), summarise,\n                 num_longoff = sum(long_glance),\n                 num_glance = length(look),\n                 mean_duration = mean(duration),\n                 total_off_time = sum(duration),\n                 DBQ_Error = mean(DBQ_E_mean),\n                 DBQ_Violation = mean(DBQ_V_mean),\n                 DBQ_Lapse = mean(DBQ_L_mean))\n\n# add task completion time\ntask.off.sum <- join(task.off.sum, tasktime.table, by = c(\"new_subject\",\"task\"))\n\n# create normalized variables\ntask.off.sum$num_glance_pm <- 60*task.off.sum$num_glance/task.off.sum$task_time\ntask.off.sum$num_long_glance_pm <- 60*task.off.sum$num_longoff/task.off.sum$task_time\ntask.off.sum$total_off_time_pm <- 60*task.off.sum$total_off_time/task.off.sum$task_time\ntask.off.sum$percentage_long_glance <- task.off.sum$num_longoff/task.off.sum$num_glance*100\n\ntask.off.sum.final <- ddply(task.off.sum, .(new_subject, age, gender, car), summarise,\n                            mean_num_longoff = mean(num_longoff),\n                            sum_num_longoff = sum(num_longoff),\n                            mean_num_off = mean(num_glance),\n                            mean_off_duration = mean(mean_duration),\n                            sd_off_duration = sd(mean_duration),\n                            mean_total_off_time = mean(total_off_time),\n                            mean_num_off_glance_pm = mean(num_glance_pm),\n                            mean_num_long_glance_pm = mean(num_long_glance_pm),\n                            mean_total_off_time_pm = mean(total_off_time_pm),\n                            mean_percentage_long_glance = mean(percentage_long_glance),\n                            DBQ_Violation = mean(DBQ_Violation),\n                            DBQ_Error = mean(DBQ_Error),\n                            DBQ_Lapse = mean(DBQ_Lapse))\n```\n\n**Machine learning approach: PART 1**\n```{r, fig.width=12, fig.height=5}\nclassdata2 <- task.off.sum.final\n# add labels\nclassdata2$class<-\"Normal glancers\"\nclassdata2$class[classdata2$mean_num_long_glance_pm > 0.3745982]<-\"Long glancers\"\nclassdata2$class_numeric<-0\nclassdata2$class_numeric[classdata2$mean_num_long_glance_pm > 0.3745982]<-1\n\n# compare sample sizes for the two groups\nl.glancer <- subset(classdata2, class_numeric==1) # N=91\nn.glancer <- subset(classdata2, class_numeric==0) # N=197\n\n# balancing by random sampling\nn.list <- sample(unique(n.glancer$new_subject), size = 91, replace = FALSE)\nn.glancer.balanced <- subset(n.glancer, new_subject%in%n.list)\n\n# final data\nclassdata.balanced <- rbind(l.glancer, n.glancer.balanced)\n\n# training a model \nset.seed(998)\ninTraining <- createDataPartition(classdata.balanced$class, p = .8, list=FALSE)\ntraining <-classdata.balanced[inTraining,]\ntesting <-classdata.balanced[-inTraining,]\ntraining$class <- as.factor(training$class)\ntesting$class <- as.factor(testing$class)\n\ntraining<-na.omit(training)\ntesting<-na.omit(testing)\n\nfitControl <- trainControl(method = \"repeatedcv\",\n                           number = 10,\n                           repeats = 100)\n\nset.seed(825)\ngbmFit1 <- train(class ~age+gender+mean_off_duration+sd_off_duration+mean_num_off_glance_pm+mean_total_off_time_pm+DBQ_Violation+DBQ_Error+DBQ_Lapse, data = training, method = \"gbm\", trControl = fitControl, verbose=FALSE)\n\n#gbmFit\ngbmImp <- varImp(gbmFit1, scale=FALSE)\nplot(gbmImp, top=9, main=\"Variable importance evaluation\")\n\n# confusion matrix\nconfusionMatrix(testing$class, predict(gbmFit1, newdata = testing))\nsum<-confusionMatrix(testing$class, predict(gbmFit1, newdata = testing))\na<-sum$table\ndf2<-melt(a, id=c(\"Reference\", \"Prediction\"))\ndf2$Prediction <- ordered(df2$Prediction, levels = c(\"Long glancers\",\"Normal glancers\"))\ndf2$Reference <- ordered(df2$Reference, levels = c(\"Normal glancers\",\"Long glancers\"))\n\nggplot(df2, aes(x = Prediction, y = Reference, label=value)) +\n  geom_tile(aes(fill = value)) +\n  scale_fill_gradient(low = 'white', high = 'grey')+theme_bw(16)+geom_text()+ggtitle(\"Confusion matrix (Accuracy = .81, Kappa = .61)\")+theme(legend.position=\"NONE\")\n```\n\n\n**Machine learning approach: PART 2**\n```{r, fig.width=12, fig.height=5}\nclassdata3 <- task.off.sum.final\n# add labels\nclassdata3$class<-\"Normal glancers\"\nclassdata3$class[classdata3$sum_num_longoff > 0]<-\"Long glancers\"\nclassdata3$class_numeric<-0\nclassdata3$class_numeric[classdata3$sum_num_longoff > 0]<-1\n\n# compare sample sizes for the two groups\nl.glancer.num <- subset(classdata3, class_numeric==1) # N=186\nn.glancer.num <- subset(classdata3, class_numeric==0) # N=102\n\n# balancing by random sampling\nl.list.num <- sample(unique(l.glancer.num$new_subject), size = 102, replace = FALSE)\nl.glancer.num.balanced <- subset(l.glancer.num, new_subject%in%l.list.num)\n\n# final data\nclassdata.num.balanced <- rbind(l.glancer.num.balanced, n.glancer.num)\n\n# training a model\nset.seed(998)\ninTraining <- createDataPartition(classdata.num.balanced$class, p = .8, list=FALSE)\ntraining <-classdata.num.balanced[inTraining,]\ntesting <-classdata.num.balanced[-inTraining,]\ntraining$class <- as.factor(training$class)\ntesting$class <- as.factor(testing$class)\n\ntraining<-na.omit(training)\ntesting<-na.omit(testing)\n\nfitControl <- trainControl(method = \"repeatedcv\",\n                           number = 10,\n                           repeats = 100)\n\nset.seed(825)\ngbmFit1 <- train(class ~age+gender+mean_off_duration+sd_off_duration+mean_num_off_glance_pm+mean_total_off_time_pm+DBQ_Violation+DBQ_Error+DBQ_Lapse, data = training, method = \"gbm\", trControl = fitControl, verbose=FALSE)\ngbmFit2 <- train(class ~age+gender+DBQ_Violation+DBQ_Error+DBQ_Lapse, data = training, method = \"gbm\", trControl = fitControl, verbose=FALSE)\n\n#gbmFit\ngbmImp <- varImp(gbmFit1, scale=FALSE)\nplot(gbmImp, top=9, main=\"Variable importance evaluation\")\n\n# confusion matrix\nconfusionMatrix(testing$class, predict(gbmFit1, newdata = testing))\nsum<-confusionMatrix(testing$class, predict(gbmFit1, newdata = testing))\na<-sum$table\ndf2<-melt(a, id=c(\"Reference\", \"Prediction\"))\ndf2$Prediction <- ordered(df2$Prediction, levels = c(\"Long glancers\",\"Normal glancers\"))\ndf2$Reference <- ordered(df2$Reference, levels = c(\"Normal glancers\",\"Long glancers\"))\n\nggplot(df2, aes(x = Prediction, y = Reference, label=value)) +\n  geom_tile(aes(fill = value)) +\n  scale_fill_gradient(low = 'white', high = 'grey')+theme_bw(16)+geom_text()+ggtitle(\"Confusion matrix (Accuracy = .82, Kappa = .64)\")+theme(legend.position=\"NONE\")\n\nt.test(mean_off_duration~class, classdata3)\nt.test(sd_off_duration~class, classdata3)\n\nt.test(mean_off_duration~class, classdata2)\nt.test(sd_off_duration~class, classdata2)\n```\n\nvarset<-c(\"new_subject\",\"age\",\"gender\",\"mean_off_duration\",\"sd_off_duration\",\"mean_total_off_time_pm\",\"mean_num_off_glance_pm\",\"DBQ_Violation\",\"DBQ_Error\",\"DBQ_Lapse\")\ntestexample <-testing[varset]\nhead(testexample)\nwrite.csv(testexample, \"~/\")\nhead(classdata3)\nggplot(classdata3, aes(x=sum_num_longoff))+geom_histogram(binwidth=1)+geom_vline(xintercept=1, colour=\"red\", linetype=2)+theme_bw(16)+xlab(\"Total number of long glances per subject\")+geom_rect(xmin=1, xmax=89, ymin=102, ymax=105,fill=\"blue\",alpha=I(.002))+ylab(\"Count\")+geom_rect(xmin=0, xmax=1, ymin=102, ymax=105,fill=\"red\",alpha=I(.002))\n\nwhich(classdata3$sum_num_longoff > 80)\nclassdata3[96,]\nggplot(classdata2, aes(x=mean_num_long_glance_pm))+geom_histogram(binwidth=0.1)+geom_vline(xintercept=0.37, colour=\"red\", linetype=2)+theme_bw(16)+xlab(\"Average number of long off-road glances per minute\")+geom_rect(xmin=0.37, xmax=5, ymin=147, ymax=150,fill=\"blue\",alpha=I(.002))+ylab(\"Count\")+geom_rect(xmin=0, xmax=0.37, ymin=147, ymax=150,fill=\"red\",alpha=I(.002))\nmean(classdata2$mean_num_long_glance_pm)\nhead(classdata2)\n\nreg.fit <- lm(mean_num_long_glance_pm~age+gender+mean_off_duration+sd_off_duration+mean_total_off_time_pm+mean_num_off_glance_pm+DBQ_Violation+DBQ_Error+DBQ_Lapse, \nreg.leap <- regsubsets(mean_num_long_glance_pm~age+gender+mean_off_duration+sd_off_duration+mean_total_off_time_pm+mean_num_off_glance_pm+DBQ_Violation+DBQ_Error+DBQ_Lapse,\ndata=classdata2)\n\nsummary(reg.fit)\nplot(reg.fit)\nsummary(reg.leap)\nplot(reg.leap, scale=\"r2\")\nreg.fit2 <- lm(sum_num_longoff~age+gender+mean_off_duration+sd_off_duration+mean_total_off_time_pm+mean_num_off_glance_pm+DBQ_Violation+DBQ_Error+DBQ_Lapse, data=classdata3)\nsummary(reg.fit2)\n\nhead(s2055)\nggplot(s2055, aes(x=duration))+geom_histogram(binwidth=0.1, fill=\"navyblue\", colour=\"black\")+theme_bw(16)+xlab(\"Off-road glance duration (sec)\")+ylab(\"Count\")\n",
    "created" : 1460043707858.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2289085656",
    "id" : "82CE99A1",
    "lastKnownWriteTime" : 1459182868,
    "path" : "~/Dropbox/Works/R codes/MIT/Publication/2016_Investigating outliers/Investigating outliers/2016 03 25 distributions of off-road glances (with Jon).Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "type" : "r_markdown"
}